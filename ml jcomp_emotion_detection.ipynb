{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644bfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89af3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fer2013.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "002a64a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a52952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "for i, row in df.iterrows():\n",
    "    k = row['pixels'].split(\" \")\n",
    "    if row['Usage']=='Training':\n",
    "        X_train.append(np.array(k))\n",
    "        Y_train.append(row['emotion'])\n",
    "    elif row['Usage'] == 'PublicTest':\n",
    "        X_test.append(np.array(k))\n",
    "        Y_test.append(row['emotion'])\n",
    "    elif row['Usage'] == 'PrivateTest':\n",
    "        X_val.append(np.array(k))\n",
    "        Y_val.append(row['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e1ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype = 'uint8')\n",
    "Y_train = np.array(Y_train, dtype = 'uint8')\n",
    "X_test = np.array(X_test, dtype = 'uint8')\n",
    "Y_test = np.array(Y_test, dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041a8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "Y_train= to_categorical(Y_train, num_classes=7)\n",
    "Y_test = to_categorical(Y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f83254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b298c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "datagen = ImageDataGenerator( rescale=1./255,rotation_range = 10,horizontal_flip = True,width_shift_range=0.1,height_shift_range=0.1,fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7a3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c216da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n",
    "test_flow = testgen.flow(X_test, Y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aff9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adb9ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu', padding = 'same', input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(512,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation = 'relu'))\n",
    "model.add(Dense(7,activation = 'softmax'))\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cea7af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "448/448 [==============================] - 53s 115ms/step - loss: 1.9456 - accuracy: 0.2523 - val_loss: 2.0690 - val_accuracy: 0.1700\n",
      "Epoch 2/100\n",
      "448/448 [==============================] - 52s 116ms/step - loss: 1.6958 - accuracy: 0.3197 - val_loss: 1.6891 - val_accuracy: 0.3600\n",
      "Epoch 3/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 1.5968 - accuracy: 0.3677 - val_loss: 1.5839 - val_accuracy: 0.3940\n",
      "Epoch 4/100\n",
      "448/448 [==============================] - 52s 116ms/step - loss: 1.5151 - accuracy: 0.4079 - val_loss: 1.5504 - val_accuracy: 0.4352\n",
      "Epoch 5/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.4342 - accuracy: 0.4421 - val_loss: 1.4072 - val_accuracy: 0.4709\n",
      "Epoch 6/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.3567 - accuracy: 0.4761 - val_loss: 1.3040 - val_accuracy: 0.5029\n",
      "Epoch 7/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.2906 - accuracy: 0.5083 - val_loss: 1.2800 - val_accuracy: 0.5157\n",
      "Epoch 8/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.2358 - accuracy: 0.5273 - val_loss: 1.1925 - val_accuracy: 0.5472\n",
      "Epoch 9/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.1921 - accuracy: 0.5464 - val_loss: 1.2079 - val_accuracy: 0.5378\n",
      "Epoch 10/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.1513 - accuracy: 0.5569 - val_loss: 1.2038 - val_accuracy: 0.5436\n",
      "Epoch 11/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.1199 - accuracy: 0.5723 - val_loss: 1.1723 - val_accuracy: 0.5626\n",
      "Epoch 12/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.0887 - accuracy: 0.5865 - val_loss: 1.1464 - val_accuracy: 0.5603\n",
      "Epoch 13/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.0723 - accuracy: 0.5921 - val_loss: 1.1434 - val_accuracy: 0.5773\n",
      "Epoch 14/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.0428 - accuracy: 0.6055 - val_loss: 1.0844 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 1.0191 - accuracy: 0.6120 - val_loss: 1.1152 - val_accuracy: 0.5988\n",
      "Epoch 16/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.9959 - accuracy: 0.6227 - val_loss: 1.1119 - val_accuracy: 0.5896\n",
      "Epoch 17/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.9809 - accuracy: 0.6272 - val_loss: 1.0972 - val_accuracy: 0.6038\n",
      "Epoch 18/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.9559 - accuracy: 0.6372 - val_loss: 1.0375 - val_accuracy: 0.6124\n",
      "Epoch 19/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.9391 - accuracy: 0.6457 - val_loss: 1.0095 - val_accuracy: 0.6291\n",
      "Epoch 20/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.9170 - accuracy: 0.6545 - val_loss: 1.0005 - val_accuracy: 0.6381\n",
      "Epoch 21/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.8998 - accuracy: 0.6588 - val_loss: 0.9965 - val_accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.8840 - accuracy: 0.6632 - val_loss: 1.0167 - val_accuracy: 0.6269\n",
      "Epoch 23/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.8679 - accuracy: 0.6753 - val_loss: 1.0305 - val_accuracy: 0.6261\n",
      "Epoch 24/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.8467 - accuracy: 0.6782 - val_loss: 1.0216 - val_accuracy: 0.6386\n",
      "Epoch 25/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.8283 - accuracy: 0.6890 - val_loss: 1.0100 - val_accuracy: 0.6342\n",
      "Epoch 26/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.8176 - accuracy: 0.6934 - val_loss: 1.0115 - val_accuracy: 0.6308\n",
      "Epoch 27/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.7963 - accuracy: 0.7005 - val_loss: 1.0144 - val_accuracy: 0.6397\n",
      "Epoch 28/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.7809 - accuracy: 0.7053 - val_loss: 0.9945 - val_accuracy: 0.6422\n",
      "Epoch 29/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.7682 - accuracy: 0.7125 - val_loss: 0.9806 - val_accuracy: 0.6509\n",
      "Epoch 30/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.7460 - accuracy: 0.7205 - val_loss: 0.9813 - val_accuracy: 0.6428\n",
      "Epoch 31/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.7333 - accuracy: 0.7274 - val_loss: 0.9843 - val_accuracy: 0.6545\n",
      "Epoch 32/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.7198 - accuracy: 0.7300 - val_loss: 0.9838 - val_accuracy: 0.6587\n",
      "Epoch 33/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.6944 - accuracy: 0.7391 - val_loss: 0.9999 - val_accuracy: 0.6556\n",
      "Epoch 34/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.6849 - accuracy: 0.7421 - val_loss: 1.0009 - val_accuracy: 0.6609\n",
      "Epoch 35/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.6694 - accuracy: 0.7484 - val_loss: 1.0147 - val_accuracy: 0.6509\n",
      "Epoch 36/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.6529 - accuracy: 0.7568 - val_loss: 1.0458 - val_accuracy: 0.6581\n",
      "Epoch 37/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.6323 - accuracy: 0.7641 - val_loss: 1.0203 - val_accuracy: 0.6631\n",
      "Epoch 38/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.6228 - accuracy: 0.7674 - val_loss: 0.9874 - val_accuracy: 0.6637\n",
      "Epoch 39/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.6061 - accuracy: 0.7709 - val_loss: 1.0672 - val_accuracy: 0.6539\n",
      "Epoch 40/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.5885 - accuracy: 0.7784 - val_loss: 1.0394 - val_accuracy: 0.6693\n",
      "Epoch 41/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.5715 - accuracy: 0.7845 - val_loss: 1.1024 - val_accuracy: 0.6551\n",
      "Epoch 42/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.5551 - accuracy: 0.7933 - val_loss: 1.0634 - val_accuracy: 0.6531\n",
      "Epoch 43/100\n",
      "448/448 [==============================] - 53s 118ms/step - loss: 0.5403 - accuracy: 0.7986 - val_loss: 1.1000 - val_accuracy: 0.6651\n",
      "Epoch 44/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.5294 - accuracy: 0.8029 - val_loss: 1.1028 - val_accuracy: 0.6570\n",
      "Epoch 45/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.5089 - accuracy: 0.8110 - val_loss: 1.1612 - val_accuracy: 0.6523\n",
      "Epoch 46/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.5034 - accuracy: 0.8122 - val_loss: 1.1748 - val_accuracy: 0.6643\n",
      "Epoch 47/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.4771 - accuracy: 0.8205 - val_loss: 1.1439 - val_accuracy: 0.6746\n",
      "Epoch 48/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.4649 - accuracy: 0.8271 - val_loss: 1.1234 - val_accuracy: 0.6707\n",
      "Epoch 49/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.4582 - accuracy: 0.8301 - val_loss: 1.1957 - val_accuracy: 0.6606\n",
      "Epoch 50/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.4439 - accuracy: 0.8359 - val_loss: 1.1168 - val_accuracy: 0.6771\n",
      "Epoch 51/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.4341 - accuracy: 0.8379 - val_loss: 1.1604 - val_accuracy: 0.6698\n",
      "Epoch 52/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.4231 - accuracy: 0.8425 - val_loss: 1.1934 - val_accuracy: 0.6676\n",
      "Epoch 53/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.4091 - accuracy: 0.8485 - val_loss: 1.1767 - val_accuracy: 0.6687\n",
      "Epoch 54/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3939 - accuracy: 0.8546 - val_loss: 1.2206 - val_accuracy: 0.6707\n",
      "Epoch 55/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3764 - accuracy: 0.8579 - val_loss: 1.2499 - val_accuracy: 0.6740\n",
      "Epoch 56/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3708 - accuracy: 0.8636 - val_loss: 1.2396 - val_accuracy: 0.6542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.3574 - accuracy: 0.8688 - val_loss: 1.3125 - val_accuracy: 0.6551\n",
      "Epoch 58/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3584 - accuracy: 0.8685 - val_loss: 1.3426 - val_accuracy: 0.6729\n",
      "Epoch 59/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3402 - accuracy: 0.8744 - val_loss: 1.3235 - val_accuracy: 0.6704\n",
      "Epoch 60/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3292 - accuracy: 0.8790 - val_loss: 1.3213 - val_accuracy: 0.6751\n",
      "Epoch 61/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3217 - accuracy: 0.8802 - val_loss: 1.3513 - val_accuracy: 0.6734\n",
      "Epoch 62/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.3172 - accuracy: 0.8836 - val_loss: 1.3698 - val_accuracy: 0.6648\n",
      "Epoch 63/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2997 - accuracy: 0.8916 - val_loss: 1.3958 - val_accuracy: 0.6595\n",
      "Epoch 64/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2878 - accuracy: 0.8943 - val_loss: 1.4385 - val_accuracy: 0.6587\n",
      "Epoch 65/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2915 - accuracy: 0.8947 - val_loss: 1.3778 - val_accuracy: 0.6748\n",
      "Epoch 66/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2768 - accuracy: 0.8975 - val_loss: 1.4397 - val_accuracy: 0.6648\n",
      "Epoch 67/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2725 - accuracy: 0.9026 - val_loss: 1.4161 - val_accuracy: 0.6840\n",
      "Epoch 68/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2648 - accuracy: 0.9033 - val_loss: 1.4278 - val_accuracy: 0.6746\n",
      "Epoch 69/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2605 - accuracy: 0.9047 - val_loss: 1.4273 - val_accuracy: 0.6687\n",
      "Epoch 70/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2550 - accuracy: 0.9052 - val_loss: 1.4656 - val_accuracy: 0.6709\n",
      "Epoch 71/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2427 - accuracy: 0.9109 - val_loss: 1.5369 - val_accuracy: 0.6609\n",
      "Epoch 72/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.2363 - accuracy: 0.9133 - val_loss: 1.5054 - val_accuracy: 0.6659\n",
      "Epoch 73/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2433 - accuracy: 0.9113 - val_loss: 1.5208 - val_accuracy: 0.6668\n",
      "Epoch 74/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2305 - accuracy: 0.9162 - val_loss: 1.5212 - val_accuracy: 0.6634\n",
      "Epoch 75/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2265 - accuracy: 0.9172 - val_loss: 1.5298 - val_accuracy: 0.6659\n",
      "Epoch 76/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2181 - accuracy: 0.9208 - val_loss: 1.5818 - val_accuracy: 0.6631\n",
      "Epoch 77/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2152 - accuracy: 0.9205 - val_loss: 1.5348 - val_accuracy: 0.6754\n",
      "Epoch 78/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2187 - accuracy: 0.9209 - val_loss: 1.4997 - val_accuracy: 0.6821\n",
      "Epoch 79/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2087 - accuracy: 0.9241 - val_loss: 1.5243 - val_accuracy: 0.6754\n",
      "Epoch 80/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.2099 - accuracy: 0.9236 - val_loss: 1.5495 - val_accuracy: 0.6815\n",
      "Epoch 81/100\n",
      "448/448 [==============================] - 53s 117ms/step - loss: 0.1987 - accuracy: 0.9296 - val_loss: 1.5766 - val_accuracy: 0.6718\n",
      "Epoch 82/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1975 - accuracy: 0.9273 - val_loss: 1.5966 - val_accuracy: 0.6626\n",
      "Epoch 83/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1988 - accuracy: 0.9287 - val_loss: 1.6423 - val_accuracy: 0.6668\n",
      "Epoch 84/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1909 - accuracy: 0.9305 - val_loss: 1.5733 - val_accuracy: 0.6712\n",
      "Epoch 85/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1876 - accuracy: 0.9308 - val_loss: 1.6510 - val_accuracy: 0.6645\n",
      "Epoch 86/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1842 - accuracy: 0.9344 - val_loss: 1.6815 - val_accuracy: 0.6623\n",
      "Epoch 87/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1825 - accuracy: 0.9352 - val_loss: 1.6865 - val_accuracy: 0.6673\n",
      "Epoch 88/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1766 - accuracy: 0.9375 - val_loss: 1.6674 - val_accuracy: 0.6684\n",
      "Epoch 89/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1796 - accuracy: 0.9354 - val_loss: 1.6482 - val_accuracy: 0.6693\n",
      "Epoch 90/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1706 - accuracy: 0.9388 - val_loss: 1.6349 - val_accuracy: 0.6768\n",
      "Epoch 91/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1686 - accuracy: 0.9388 - val_loss: 1.7350 - val_accuracy: 0.6748\n",
      "Epoch 92/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1732 - accuracy: 0.9375 - val_loss: 1.6625 - val_accuracy: 0.6751\n",
      "Epoch 93/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1649 - accuracy: 0.9406 - val_loss: 1.7095 - val_accuracy: 0.6754\n",
      "Epoch 94/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1643 - accuracy: 0.9401 - val_loss: 1.7473 - val_accuracy: 0.6729\n",
      "Epoch 95/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1611 - accuracy: 0.9418 - val_loss: 1.7104 - val_accuracy: 0.6737\n",
      "Epoch 96/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1583 - accuracy: 0.9436 - val_loss: 1.7033 - val_accuracy: 0.6773\n",
      "Epoch 97/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1489 - accuracy: 0.9462 - val_loss: 1.7569 - val_accuracy: 0.6723\n",
      "Epoch 98/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1499 - accuracy: 0.9459 - val_loss: 1.8120 - val_accuracy: 0.6707\n",
      "Epoch 99/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1539 - accuracy: 0.9434 - val_loss: 1.7613 - val_accuracy: 0.6737\n",
      "Epoch 100/100\n",
      "448/448 [==============================] - 52s 117ms/step - loss: 0.1489 - accuracy: 0.9466 - val_loss: 1.7744 - val_accuracy: 0.6721\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100  \n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10), ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "history = model.fit(train_flow,steps_per_epoch=len(X_train) / batch_size, epochs=num_epochs,  verbose=1,  validation_data=test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bec650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emotiondet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6dedb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('emotiondet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c53bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db19aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    res, frame = cap.read()\n",
    "    height, width , channel = frame.shape\n",
    "    gray_image= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "    try:\n",
    "        for (x,y,w,h) in faces:\n",
    "            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "            roi_gray = gray_image[y-5:y+h+5,x-5:x+w+5]\n",
    "            roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "            image_pixels = img_to_array(roi_gray)\n",
    "            image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
    "            image_pixels /= 255\n",
    "            predictions = model.predict(image_pixels)\n",
    "            max_index = np.argmax(predictions[0])\n",
    "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            emotion_prediction = emotion_detection[max_index]\n",
    "            frame = cv2.putText(frame,emotion_prediction,(x,y),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "    except:\n",
    "        pass\n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7430d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
